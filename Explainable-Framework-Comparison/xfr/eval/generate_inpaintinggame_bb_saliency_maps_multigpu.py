#!/usr/bin/env python3
import os
import glob
import dill as pickle
import multiprocessing as mp
from multiprocessing import Pool
from functools import partial
from pprint import pprint
import signal
import subprocess
import glob
import pandas as pd
import datetime
import pytz
import random
import torch
import numpy as np

import xfr
from xfr import inpaintgame2_dir
from xfr import xfr_root
from xfr import inpaintgame_saliencymaps_dir

from create_wbnet import create_wbnet
from xfr.utils import iterate_param_sets
from xfr.utils import prune_unneeded_exports
from xfr.utils import normalize_gpus
from xfr.inpainting_game.generate_blackbox_saliency import generate_bb_smaps

def randomly(seq):
    # https://stackoverflow.com/a/9253366/249226
    shuffled = list(seq)
    random.shuffle(shuffled)
    return iter(shuffled)


def run_experiment(params, params_export, gpu_queue):
    import gc
    import imp

    gpu_id = gpu_queue.get()
    process = None
    success = False
    try:
        # taa: This is a physical GPU ID, as generated by normalize_gpus() call
        # in run_experiments.
        # print("Running on GPU {}".format(gpu_id))
        # os.environ['CUDA_VISIBLE_DEVICES'] = str(gpu_id)

        if torch.cuda.is_available():
            device = torch.device("cuda:{}".format(gpu_id))
            print("Running on {}".format(device))
        else:
            device = torch.device("cpu")
            print("Running on CPU")

        params['EXPER_DIR'] = (  # output directory
            'Note_20190802_Masks_for_Inpainting/' +
            ','.join([
                str(params[k][0]).replace('/', '-') for k in params_export if len(params[k])==1
            ]))

        out_dir = os.path.join(
            os.path.dirname(__file__),
            'generated',
            ('{EXPER_DIR}'
            ).format(**params))

        net_name = params['WB_NET'][0]
        ebp_version = int(params['EBP_VER'][0])
        wb = create_wbnet(net_name, ebp_version=ebp_version, device=device)

        def bb_fn(probes, gallery):
            """ For each probe, calculate the scores for matching to gallery.

                Returns np.array with dimensions (len(probes), len(gallery))
            """
            # Send gallery images forward through the network
            if isinstance(gallery[0], np.ndarray):
                # If third channel equals 3, assume images need preprocessing
                if gallery[0].shape[2] == 3:
                    gallery = [wb.convert_from_numpy(im)[0] for im in gallery]
            gallery_vecs = wb.embeddings(gallery)

            # Send probe images forward through the network
            if isinstance(probes[0], np.ndarray):
                # If third channel equals 3, assume images need preprocessing
                if probes[0].shape[2] == 3:
                    probes = [wb.convert_from_numpy(im)[0] for im in probes]
            probe_vecs = wb.embeddings(probes)

            # Compute score
            L2_similarity = lambda x, y: (
                1.0 - 0.5 * np.linalg.norm(
                    (x/np.linalg.norm(x,axis=1)[:,None])[:,None] -
                    y/np.linalg.norm(y,axis=1)[:,None],
                    axis=2)
            )

            scores = L2_similarity(probe_vecs, gallery_vecs)
            return scores

        generate_bb_smaps(
            bb_fn, wb.convert_from_numpy,
            net_name,
            img_base='img/%d' % int(params['IMG_NUM'][0]),
            subj_id=params['SUBJECT_ID'][0],
            mask_id=params['MASK_ID'][0],
            ebp_ver=ebp_version,
            overwrite=params['overwrite'][0],
            device=device,
            rise_scale=params['RISE_SCALE'][0],
        )
        success = True

    except TypeError as e:
        print("\n\n ERROR {} detected. The parameters are:".format(e))
        pprint(params)
        if params['debug']:
            raise e
    except Exception as e:
        print("ERROR: {}".format(e))
        if params['debug']:
            raise e
    finally:
        # process.terminate()
        # try:
        #     if process is not None:
        #         process.kill()
        # except OSError: # if process has already ended, don't throw error?
        #     pass
        gpu_queue.put(gpu_id)
    return success, (params, params_export)

def run_experiments(params):
    params['overwrite'] = [params['overwrite']]
    oldGpus = params['gpus']
    newGpus = normalize_gpus(params['gpus'], setEnviron=False)
    m = mp.Manager()
    gpu_queue = m.Queue()

    for idx, gpu_id in enumerate(newGpus):
        print('Queueing GPU resource %d (%d)' % (int(gpu_id), oldGpus[idx]))
        gpu_queue.put(gpu_id)
    req_scale = (
        lambda params:
        params['MASKS_CONSTRUCTION'][0].lower() not in [
            'bbnet_mean_ebp', 'facial_regions'])

    params_export = [
        'SUBJECT_ID',
        'MASK_ID',
        'IMG_NUM',
        'WB_NET',
        'EBP_VER',
        'RISE_SCALE',
        'overwrite',
    ]
    # if params['SUBJECTS'] is None:
    #     params['SUBJECTS'] = []
    #     for subj_csv in params['SUBJ_CSV']:
    #         subj_data = pd.read_csv(subj_csv)
    #         params['SUBJECTS'].extend((
    #             subj_data['SUBJECT_ID'].map(str) + '/' +
    #             subj_data['ORIGINAL_FILE']).values
    #         )
    net_ds = {}
    subjects = set()
    for net_name in params['WB_NET']:
        ijbc_ds = pd.read_csv(
                os.path.join(
                    inpaintgame2_dir,
                    'filtered_masks_threshold-{}.csv'.format(net_name)
                ))

        ijbc_ds['IMG_NUM'] = [
            int(os.path.basename(fn))
            for fn in ijbc_ds['ORIGINAL_BASENAME'].values]

        net_ds[net_name] = ijbc_ds
        subjects.update(ijbc_ds['SUBJECT_ID'].unique().tolist())

    if params['SUBJECT_ID'] is None:
        params['SUBJECT_ID'] = list(subjects)
        params['SUBJECT_ID'].sort()
        params['SUBJECT_ID'] = [str(sid) for sid in params['SUBJECT_ID']]

    def valid_imgnums(net_ds, params_):
        ijbc_ds = net_ds[params_['WB_NET'][0]]
        subset = ijbc_ds.loc[
            (ijbc_ds['SUBJECT_ID'] == int(params_['SUBJECT_ID'][0])) &
            (ijbc_ds['MASK_ID'] == int(params_['MASK_ID'][0])) &
            (ijbc_ds['TRIPLET_SET'] == 'PROBE')
        ]
        img_nums = subset['IMG_NUM'].unique()
        if params_['filter_img_nums']:
            img_nums = [img for img in img_nums if img in
                        params_['filter_img_nums']]
        return img_nums

    if not params['debug']:
        original_sigint_handler = signal.signal(signal.SIGINT, signal.SIG_IGN)
        pool = Pool(len(params['gpus']))
        signal.signal(signal.SIGINT, original_sigint_handler)
        try:
            multiple_results = []
            param_iter = iterate_param_sets(params, params_export)
            if params['shuffle']:
                param_iter = randomly(param_iter)
            for params_ in param_iter:
                img_nums = valid_imgnums(net_ds, params_)
                # ijbc_ds = net_ds[params_['WB_NET'][0]]
                # subset = ijbc_ds.loc[
                #     (ijbc_ds['SUBJECT_ID'] == int(params_['SUBJECT_ID'][0])) &
                #     (ijbc_ds['MASK_ID'] == int(params_['MASK_ID'][0])) &
                #     (ijbc_ds['TRIPLET_SET'] == 'PROBE')
                # ]
                # img_nums = subset['IMG_NUM'].unique()
                for img_num in img_nums:
                    _params_ = params_.copy()
                    _params_['IMG_NUM'] = [str(img_num)]

                    params_export_ = prune_unneeded_exports(
                        params_export, _params_)

                    multiple_results.append(
                        pool.apply_async(
                            run_experiment,
                            args=(_params_, params_export_),
                            kwds={'gpu_queue':gpu_queue},
                        )
                    )
            for ret in multiple_results:
                success, (params_, params_export_) = ret.get(999999999)
                if not success:
                    print('Process failed! Parameters:')
                    pprint(params_)
        except KeyboardInterrupt:
            print('Caught Keyboard interrupt signal.')
            pool.terminate()
        else:
            print('Finishing multiprocessing ...')
            pool.close()
            print('Finished multiprocessing normally'
                  ' (some processes may still be running).')
        pool.join()
        print('Joined pool')
    else:
        for params_ in iterate_param_sets(params, params_export):
            img_nums = valid_imgnums(net_ds, params_)
            for img_num in img_nums:
                _params_ = params_.copy()
                _params_['IMG_NUM'] = [str(img_num)]

                params_export_ = prune_unneeded_exports(
                    params_export, _params_)

                run_experiment(_params_, params_export_, gpu_queue)

if __name__ == '__main__':
    import argparse
    parser = argparse.ArgumentParser(
        'Script for generating blakbox saliency maps in parallel.')

    parser.add_argument(
        '--gpu',
        '--gpus',
        dest='gpus',
        default=None,
        nargs='+',
        type=int,
        help='space separated list of GPU ids to use.'
    )

    parser.add_argument(
        '--debug',
        action='store_true',
        help='disable multiprocessing to make script easier to debug',
    )
    parser.add_argument(
        '--dry-run',
        action='store_true',
        dest='dry_run',
    )

    parser.add_argument(
        '--subjects', nargs='+', dest='SUBJECT_ID',
        default=None,
        help='restrict processing to specific subjects',
    )
    parser.add_argument(
        '--img-num', nargs='*', dest='filter_img_nums',
        default=None,
        type=int,
        help='restrict processing to specific subjects',
    )
    parser.add_argument(
        '--ebp-ver', nargs='+', dest='EBP_VER',
        default=['6'],
        help='EBP version to use (leave as default, shouldn\'t impact '
        'blackbox results).',
        )
    parser.add_argument(
        '--scale', nargs='+', dest='RISE_SCALE',
        # default=['6', '12', '18', '24', '32'],
        default=[12],
        type=int,
        help='size of the masking elements used',
        )
    parser.add_argument(
        '--mask', nargs='+', dest='MASK_ID',
        default=[
            '{:05}'.format(mask_id)  for mask_id in range(10)
        ],
        help='restrict processing to specific masks, zero padded',
    )
    parser.add_argument(
        '--net', nargs='+',
        default=['resnetv4_pytorch'],
        dest='WB_NET',
        help='network to use',
    )

    # parser.add_argument('--no-overwrite',
    #                     dest='overwrite',
    #                     action='store_false')
    parser.add_argument(
        '--overwrite',
        action='store_true',
        help='force recalculation of saliency maps'
    )
    parser.add_argument(
        '--shuffle',
        dest='shuffle',
        action='store_true',
        help='generate the saliency maps in random order, useful if running '
        'results on multiple computers and saving to shared directory.',
    )
    parser.add_argument(
        '--script', dest='file',
        default=None,
        help='override the single-gpu script to call (advanced)',
    )

    args = parser.parse_args()
    params = vars(args)

    if params['gpus'] is None:
        params['gpus'] = [*range(torch.cuda.device_count())]

    run_experiments(params)
